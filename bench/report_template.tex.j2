%% report_template.tex.j2 -- Jinja2 LaTeX template for the matryoshka
%% comparative benchmark report.
%%
%% Custom Jinja2 delimiters for LaTeX compatibility:
%%   BLOCK, VAR, and comment delimiters with backslash prefix.
%%
\documentclass[11pt,a4paper]{article}

\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage[colorlinks=true,linkcolor=matryoshkacolor,urlcolor=matryoshkacolor,citecolor=matryoshkacolor]{hyperref}
\usepackage{fancyhdr}
\usepackage{siunitx}
\usepackage[table]{xcolor}
\usepackage{longtable}
\usepackage{float}
\usepackage{enumitem}
\usepackage{microtype}
\usepackage{listings}
\usepackage{caption}
\usepackage{colortbl}

%% ── Colours ─────────────────────────────────────────────────────────────────
\definecolor{matryoshkacolor}{RGB}{31,119,180}
\definecolor{stdsetcolor}{RGB}{214,39,40}
\definecolor{tlxcolor}{RGB}{148,103,189}
\definecolor{artcolor}{RGB}{255,127,14}
\definecolor{abseilcolor}{RGB}{44,160,44}
\definecolor{rowhl}{RGB}{220,230,242}

%% ── Page style ──────────────────────────────────────────────────────────────
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small Matryoshka B+ Tree Benchmark Report}
\fancyhead[R]{\small \VAR{date}}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\lstset{basicstyle=\ttfamily\small, breaklines=true, frame=single, columns=fullflexible}
\sisetup{group-separator={,}, group-minimum-digits=4}

\begin{document}

%% ═══════════════════════════════════ Title Page ═════════════════════════════
\begin{titlepage}
\centering
\vspace*{3cm}
{\Huge\bfseries Matryoshka B+ Tree:\\[0.3em]
Insert/Delete Performance Report\par}
\vspace{1.5cm}
{\Large Comparative Benchmark Results\par}
\vspace{2cm}
{\large \VAR{date}\par}
\vspace{3cm}
\begin{tabular}{ll}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
CPU       & \VAR{sysinfo.cpu} \\
L1d Cache & \VAR{sysinfo.l1d} \\
L2 Cache  & \VAR{sysinfo.l2} \\
L3 Cache  & \VAR{sysinfo.l3} \\
Kernel    & \VAR{sysinfo.kernel} \\
Page Size & \VAR{sysinfo.page_size} \\
\bottomrule
\end{tabular}
\vfill
{\small Generated by \texttt{bench\_compare} --- matryoshka project\par}
\end{titlepage}

%% ═══════════════════════════════════ TOC ════════════════════════════════════
\tableofcontents
\newpage

%% ═══════════════════════════════════ Introduction ══════════════════════════
\section{Introduction}

This report evaluates the \textcolor{matryoshkacolor}{\textbf{matryoshka}}
B+ tree --- a B+ tree whose page-sized leaf nodes contain nested B+ sub-trees
of cache-line-sized (64\,B) sub-nodes, with SIMD-accelerated search at every
level --- against several tree and ordered-map libraries on \emph{insert-heavy}
and \emph{delete-heavy} workloads.  Goals:
\begin{enumerate}[nosep]
  \item Quantify the modification throughput gap across dataset sizes
        (\num{65536} to \num{16777216} keys).
  \item Identify micro-architectural bottlenecks (cache misses, TLB
        pressure, branch misprediction) that explain the differences.
\end{enumerate}
All measurements use \texttt{clock\_gettime(CLOCK\_MONOTONIC)}.  Results
are reported as \si{Mop/s} and \si{ns/op}.

%% ═══════════════════════════════════ Libraries ═════════════════════════════
\section{Library Descriptions}

\begin{table}[H]
\centering
\caption{Libraries under test.}
\label{tab:libraries}
\begin{tabular}{lll}
\toprule
\textbf{Name} & \textbf{Label} & \textbf{Description} \\
\midrule
\BLOCK{for lib in libraries}
\texttt{\VAR{lib.name}} & \VAR{lib.label} & \VAR{lib.description} \\
\BLOCK{endfor}
\bottomrule
\end{tabular}
\end{table}

%% ═══════════════════════════════════ Workloads ═════════════════════════════
\section{Workload Descriptions}

\begin{table}[H]
\centering
\caption{Benchmark workloads.}
\label{tab:workloads}
\begin{tabular}{lp{10cm}}
\toprule
\textbf{Workload} & \textbf{Description} \\
\midrule
\texttt{seq\_insert}
  & Insert $N$ keys in ascending order. Exercises append paths. \\
\texttt{rand\_insert}
  & Insert $N$ unique keys in random order. Stresses leaf splits. \\
\texttt{ycsb\_a}
  & 95\% insert / 5\% search. Write-dominated OLTP model. \\
\texttt{rand\_delete}
  & Bulk-load $N$ sorted keys, delete all in random order. \\
\texttt{mixed}
  & Bulk-load $N$ keys, then $N$ alternating insert/delete ops. \\
\texttt{ycsb\_b}
  & Bulk-load $N$ keys, then 50\% delete / 50\% search. \\
\texttt{search\_after\_churn}
  & Bulk-load $N$ keys, $N/2$ mixed churn (untimed), then
    \num{5000000} random predecessor searches. \\
\bottomrule
\end{tabular}
\end{table}

%% ═══════════════════════════════════ Insert-Heavy Results ══════════════════
\section{Results: Insert-Heavy Workloads}

\subsection{Sequential Insert}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{\VAR{chart_bar_seq_insert}}
\caption{Sequential insert throughput (Mop/s).}
\label{fig:bar_seq_insert}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{\VAR{chart_scale_seq_insert}}
\caption{Sequential insert scaling.}
\label{fig:scale_seq_insert}
\end{figure}

\subsection{Random Insert}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{\VAR{chart_bar_rand_insert}}
\caption{Random insert throughput (Mop/s).}
\label{fig:bar_rand_insert}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{\VAR{chart_scale_rand_insert}}
\caption{Random insert scaling.}
\label{fig:scale_rand_insert}
\end{figure}

\subsection{YCSB-A (95\% Insert / 5\% Search)}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{\VAR{chart_bar_ycsb_a}}
\caption{YCSB-A throughput (Mop/s).}
\label{fig:bar_ycsb_a}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{\VAR{chart_scale_ycsb_a}}
\caption{YCSB-A scaling.}
\label{fig:scale_ycsb_a}
\end{figure}

%% ═══════════════════════════════════ Delete-Heavy Results ══════════════════
\section{Results: Delete-Heavy Workloads}

\subsection{Random Delete}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{\VAR{chart_bar_rand_delete}}
\caption{Random delete throughput (Mop/s).}
\label{fig:bar_rand_delete}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{\VAR{chart_scale_rand_delete}}
\caption{Random delete scaling.}
\label{fig:scale_rand_delete}
\end{figure}

\subsection{Mixed Insert/Delete}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{\VAR{chart_bar_mixed}}
\caption{Mixed insert/delete throughput (Mop/s).}
\label{fig:bar_mixed}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{\VAR{chart_scale_mixed}}
\caption{Mixed insert/delete scaling.}
\label{fig:scale_mixed}
\end{figure}

\subsection{YCSB-B (50\% Delete / 50\% Search)}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{\VAR{chart_bar_ycsb_b}}
\caption{YCSB-B throughput (Mop/s).}
\label{fig:bar_ycsb_b}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{\VAR{chart_scale_ycsb_b}}
\caption{YCSB-B scaling.}
\label{fig:scale_ycsb_b}
\end{figure}

%% ═══════════════════════════════════ Search After Churn ════════════════════
\section{Results: Search After Churn}

The \texttt{search\_after\_churn} workload measures pure search
throughput on a tree that has undergone insert/delete churn,
isolating search performance from modification cost.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{\VAR{chart_bar_search_after_churn}}
\caption{Search throughput after churn (Mop/s).}
\label{fig:bar_search_after_churn}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{\VAR{chart_scale_search_after_churn}}
\caption{Search-after-churn scaling.}
\label{fig:scale_search_after_churn}
\end{figure}

%% ═══════════════════════════════════ Hardware Counters ═════════════════════
\section{Hardware Counter Analysis}

\BLOCK{if chart_perf}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{\VAR{chart_perf}}
\caption{Hardware counters: dTLB miss rate, LLC miss rate, IPC,
         branch misprediction rate.}
\label{fig:perf_counters}
\end{figure}
\BLOCK{endif}

\subsection{dTLB Miss Rate}
Matryoshka's arena allocator places leaf nodes in contiguous 2\,MiB
superpage-aligned regions.  At $N = \num{\VAR{largest_n}}$, matryoshka's
dTLB miss rate is \VAR{matryoshka_dtlb_miss_rate} per \num{1000} ops,
versus \VAR{stdset_dtlb_miss_rate} for \texttt{std::set}.  Red-black
tree pointer chasing touches a new TLB entry per level; matryoshka
confines each leaf search to a single 4\,KiB page.

\subsection{LLC Miss Rate}
Matryoshka packs up to 855 keys per 4\,KiB page using a nested B+
sub-tree of cache-line sub-nodes.  \texttt{std::set} requires one
40--48\,B heap node per key.  At $N = \num{\VAR{largest_n}}$:
\VAR{matryoshka_llc_miss_rate} LLC misses/\num{1000}\,ops (matryoshka)
vs.\ \VAR{stdset_llc_miss_rate} (\texttt{std::set}).

\subsection{IPC}
SIMD search at every level (CL leaves, CL internals, outer internal
nodes) achieves IPC of \VAR{matryoshka_ipc} via pipelined
\texttt{\_mm\_cmpgt\_epi32}/\texttt{\_mm\_movemask\_ps} without
data-dependent branches.  Insert and delete paths also benefit from
SIMD navigation through the CL sub-tree to locate the target sub-node.

\subsection{Branch Misprediction}
SIMD mask arithmetic replaces conditional branches during search,
yielding near-zero misprediction.  Modification operations navigate the
CL sub-tree using the same SIMD search, with only the final CL leaf
insert/delete using scalar \texttt{memmove} on $\le 14$ keys.

%% ═══════════════════════════════════ Profiling ═════════════════════════════
\section{Profiling: Hot Functions}

\begin{table}[H]
\centering
\caption{Top functions (\texttt{perf record}, rand\_insert, $N{=}\num{1048576}$).}
\label{tab:profile}
\begin{tabular}{rll}
\toprule
\textbf{\% Overhead} & \textbf{Function} & \textbf{Source} \\
\midrule
\BLOCK{for fn in profile_functions}
\num{\VAR{fn.overhead}}\% & \texttt{\VAR{fn.name}} & \texttt{\VAR{fn.source}} \\
\BLOCK{endfor}
\bottomrule
\end{tabular}
\end{table}

The hot functions are the page-level sub-tree operations:
\texttt{mt\_page\_insert} and \texttt{mt\_page\_delete} navigate the CL
sub-tree via SIMD search, then perform a scalar insert or delete within
a single 64\,B cache-line sub-node.  CL sub-node splits and merges
occur only on overflow or underflow.

%% ═══════════════════════════════════ Results Table ═════════════════════════
\section{Detailed Results Table}

Matryoshka rows highlighted in \colorbox{rowhl}{blue}.

\begin{longtable}{llrS[table-format=4.2]S[table-format=6.1]}
\caption{Full benchmark results.\label{tab:results}} \\
\toprule
\textbf{Library} & \textbf{Workload} & \textbf{N} &
  {\textbf{Mop/s}} & {\textbf{ns/op}} \\
\midrule
\endfirsthead
\caption[]{Full benchmark results (continued).} \\
\toprule
\textbf{Library} & \textbf{Workload} & \textbf{N} &
  {\textbf{Mop/s}} & {\textbf{ns/op}} \\
\midrule
\endhead
\midrule
\multicolumn{5}{r}{\emph{Continued on next page}} \\
\bottomrule
\endfoot
\bottomrule
\endlastfoot
\BLOCK{for r in results}
\BLOCK{if r.library == 'matryoshka'}
\rowcolor{rowhl}
\BLOCK{endif}
\texttt{\VAR{r.library}} & \texttt{\VAR{r.workload}} &
  \num{\VAR{r.n}} & \VAR{r.mops} & \VAR{r.ns_per_op} \\
\BLOCK{endfor}
\end{longtable}

%% ═══════════════════════════════════ Analysis ══════════════════════════════
\section{Analysis and Diagnosis}

\subsection{Nested Sub-Tree Modification Cost}

Each insert or delete navigates the page-level CL sub-tree (2--3 SIMD
comparisons on 12--15 keys per level) to a target CL leaf, then performs
a scalar \texttt{memmove} of at most 14 keys within that 64\,B
cache-line sub-node.  The cost per modification is
$O(h_s \times b)$ where $h_s \le 2$ is the sub-tree height and
$b = 15$ is the CL leaf capacity --- roughly 30--45 key touches.

CL sub-node splits and merges occur only when a CL leaf overflows (15
keys) or underflows ($< 7$ keys).  Page-level splits (extracting all
keys and dividing across two pages) occur only when all 63 CL slots are
exhausted.  These are standard B+ tree structural operations, not
full-page rebuilds.

Matryoshka achieves \VAR{matryoshka_rand_insert_mops} Mop/s on random
insert ($N{=}\num{1048576}$), vs.\ \VAR{stdset_rand_insert_mops} Mop/s
(\texttt{std::set}) and \VAR{best_competitor_rand_insert_mops} Mop/s
(fastest B-tree competitor).

\subsection{SIMD at Every Level}

SIMD \texttt{\_mm\_cmpgt\_epi32}/\texttt{\_mm\_movemask\_ps} is used
for search within CL leaves (15 keys), CL internal nodes (12 separator
keys), and outer internal nodes ($\le 339$ keys).  Unlike a flat
SIMD-blocked layout, the nested design retains SIMD benefits for both
search \emph{and} the navigation phase of insert/delete.

Search-after-churn throughput is \VAR{matryoshka_search_mops} Mop/s at
$N{=}\num{1048576}$.

\subsection{Arena Allocator and TLB Effects}

The arena allocator places leaves in 2\,MiB hugepage-backed regions
via \texttt{mmap(MAP\_HUGETLB)}, falling back to
\texttt{posix\_memalign} + \texttt{madvise(MADV\_HUGEPAGE)}:
\begin{itemize}[nosep]
  \item \textbf{Reduced dTLB misses}: one 2\,MiB hugepage covers 512
        leaf pages.  dTLB rate: \VAR{matryoshka_dtlb_miss_rate}/\num{1000}
        ops vs.\ \VAR{stdset_dtlb_miss_rate} for \texttt{std::set}.
  \item \textbf{Spatial locality}: co-located leaves benefit sequential
        scans and range iteration.
\end{itemize}

\subsection{Where std::set Falls Behind}

\texttt{std::set} (red-black tree) suffers from pointer chasing (one
cache miss per level), poor spatial locality, and high per-node overhead
(40--48\,B/key vs.\ 4\,B in matryoshka).  Its $O(\log N)$ insert
involves a constant-factor pointer update but pays a cache miss at
every tree level.

\subsection{Where TLX and Abseil Compete}

Both use sorted-array B-tree leaves with \texttt{memmove} insert ($B
\approx 64$--$256$).  They stay within \VAR{btree_insert_gap_pct}\% of
each other.  Matryoshka is competitive on insert-heavy workloads thanks
to the nested sub-tree design, though sorted-array leaves have a simpler
constant factor for small \texttt{memmove} operations.  Neither TLX nor
Abseil uses SIMD for in-leaf search.

\subsection{ART's Radix Approach}

ART performs $O(\text{key\_length})$ operations independent of $N$.  For
4-byte keys it traverses $\le 4$ levels with compact node arrays (4--256
entries).  Insert and delete are cache-efficient, but ART lacks native
predecessor search, so \texttt{search\_after\_churn} uses point lookups.

\subsection{Overall Assessment}

The matryoshka nesting design achieves competitive insert and delete
throughput while preserving SIMD-accelerated search at every level of
the hierarchy.  Each modification touches a single cache-line sub-node
rather than rebuilding an entire page, yielding throughput within
\VAR{insert_slowdown_factor}$\times$ of the best B-tree competitor on
insert-heavy workloads and \VAR{delete_slowdown_factor}$\times$ on
delete-heavy workloads at the largest dataset size ($N{=}\num{\VAR{largest_n}}$).

%% ═══════════════════════════════════ Recommendations ═══════════════════════
\section{Future Directions}

\subsection{Deeper Nesting: Superpage-Level Sub-Trees}

The current design nests CL sub-nodes within 4\,KiB pages.  A natural
extension is to nest 4\,KiB page sub-nodes within 2\,MiB superpages,
adding a third level to the matryoshka hierarchy.  This would reduce
outer-tree height and confine more operations within a single TLB entry.
\texttt{mt\_hierarchy\_init\_superpage} provides the skeleton for this.

\subsection{Wider SIMD: AVX2 and AVX-512}

The current CL sub-nodes are sized for SSE2 (128-bit).  AVX2 (256-bit)
could double the keys per SIMD comparison, reducing sub-tree height.
AVX-512 would enable 512-bit (one full cache line) operations, though
the CL sub-node format would need restructuring.

\subsection{Batch Insert API}

Provide \texttt{matryoshka\_insert\_batch(tree, keys, k)}: sort incoming
keys, route each to its target CL leaf, and batch the insertions to
amortise sub-tree navigation.  Useful for bulk-loading from unsorted
input without pre-sorting.

\subsection{Variable-Length Keys}

The current 4-byte \texttt{int32\_t} key format could be extended to
variable-length keys by storing key offsets or using indirection within
CL sub-nodes.  This would broaden applicability at the cost of some
cache efficiency.

%% ═══════════════════════════════════ References ════════════════════════════
\section*{References}
\addcontentsline{toc}{section}{References}

\begin{enumerate}[label={[\arabic*]}, nosep, leftmargin=2em]
  \item \label{ref:fast}
        C.~Kim, J.~Chhugani, N.~Satish, E.~Sedlar, A.~D.~Nguyen,
        T.~Kaldewey, V.~W.~Lee, S.~A.~Brandt, and P.~Dubey.
        \emph{FAST: Fast Architecture Sensitive Tree Search on Modern
        CPUs and GPUs.}  SIGMOD~'10, pp.~339--350, 2010.
  \item \label{ref:btree}
        R.~Bayer and E.~McCreight.
        \emph{Organization and Maintenance of Large Ordered Indexes.}
        Acta Informatica, 1(3):173--189, 1972.
  \item \label{ref:art}
        V.~Leis, A.~Kemper, and T.~Neumann.
        \emph{The Adaptive Radix Tree: ARTful Indexing for Main-Memory
        Databases.}  ICDE~'13, pp.~38--49, 2013.
  \item \label{ref:cssbtree}
        J.~Rao and K.~A.~Ross.
        \emph{Making B+-Trees Cache Conscious in Main Memory.}
        SIGMOD~'00, pp.~475--486, 2000.
\end{enumerate}

\end{document}
